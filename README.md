# ğŸ“š Masal DiyarÄ± Bilgi AsistanÄ± (RAG Chatbot)

## Proje TanÄ±mÄ± ve AmacÄ±

Bu proje, belirlenen masal metinlerini (PDF ve TXT formatÄ±nda) kullanarak doÄŸal dil sorularÄ±na kanÄ±ta dayalÄ± cevaplar Ã¼reten, **Retrieval-Augmented Generation (RAG)** mimarisine dayalÄ± bir Chatbot uygulamasÄ±dÄ±r. 

Uygulama, lokal vektÃ¶rleme (embedding) kullanarak Google API kotasÄ±na takÄ±lmadan Ã§alÄ±ÅŸÄ±rken, cevap Ã¼retimi iÃ§in Gemini'nin gÃ¼Ã§lÃ¼ BÃ¼yÃ¼k Dil Modeli (LLM) yeteneklerini kullanÄ±r. Projenin amacÄ±, yapay zekanÄ±n sadece genel bilgiye deÄŸil, aynÄ± zamanda Ã¶zel ve kÄ±sÄ±tlÄ± veri setlerine (Masal DiyarÄ±) dayalÄ± olarak da doÄŸru ve alakalÄ± cevaplar Ã¼retebildiÄŸini gÃ¶stermektir.

---

## âš™ï¸ KullanÄ±lan Teknolojiler

Bu RAG projesi, en gÃ¼ncel ve sektÃ¶r standardÄ± araÃ§larÄ± kullanarak geliÅŸtirilmiÅŸtir.

| Teknoloji | TÃ¼rÃ¼ | AmaÃ§ ve RolÃ¼ |
| :--- | :--- | :--- |
| **Python 3.10+** | Programlama Dili | Projenin temel geliÅŸtirme ortamÄ±. |
| **Streamlit** | Web ArayÃ¼zÃ¼ | Chatbot arayÃ¼zÃ¼nÃ¼n oluÅŸturulmasÄ± ve kullanÄ±cÄ± etkileÅŸiminin saÄŸlanmasÄ±. |
| **LangChain** | Ã‡atÄ± (Framework) | RAG zincirinin (LLM, Embeddings, VektÃ¶r VeritabanÄ±) yÃ¶netimi ve koordinasyonu. |
| **Google Gemini API** | LLM | KullanÄ±cÄ±nÄ±n sorusuna nihai, akÄ±cÄ± ve anlamlÄ± cevabÄ± Ã¼retme (Model: `gemini-2.5-flash`). |
| **Sentence-Transformers** | Embedding Model | Metinleri yÃ¼ksek boyutlu vektÃ¶rlere Ã§evirme (Model: `all-MiniLM-L6-v2`). **Lokal** Ã§alÄ±ÅŸarak API maliyetini ve kotasÄ±nÄ± ortadan kaldÄ±rÄ±r. |
| **Pypdf & LangChain Loaders** | Veri Ä°ÅŸleme | PDF ve TXT gibi yapÄ±landÄ±rÄ±lmamÄ±ÅŸ masal verilerinin uygulamaya yÃ¼klenmesi. |
| **Conda / Pip** | Paket YÃ¶neticisi | Proje baÄŸÄ±mlÄ±lÄ±klarÄ±nÄ±n yÃ¶netilmesi ve ortamÄ±n izole edilmesi. |

---

## ğŸ§  Ã‡Ã¶zÃ¼m Mimarisi (RAG Zinciri)

Proje, iki aÅŸamalÄ± gÃ¼Ã§lÃ¼ bir Bilgi Alma ArtÄ±rÄ±mlÄ± Ãœretim (RAG) mimarisini takip eder:

1.  **Veri YÃ¼kleme ve ParÃ§alama (Ingestion):**
    * **Girdi:** `masallar/` klasÃ¶rÃ¼ndeki tÃ¼m PDF ve TXT dosyalarÄ±.
    * **ParÃ§alama:** `RecursiveCharacterTextSplitter` kullanÄ±larak metinler anlam bÃ¼tÃ¼nlÃ¼ÄŸÃ¼nÃ¼ koruyacak ÅŸekilde kÃ¼Ã§Ã¼k parÃ§alara (chunks) ayrÄ±lÄ±r.
2.  **Lokal VektÃ¶rleme ve VeritabanÄ± (Indexing):**
    * **Embedding:** ParÃ§alanan her metin parÃ§asÄ±, **lokal olarak** Ã§alÄ±ÅŸan `all-MiniLM-L6-v2` modeli ile sayÄ±sal vektÃ¶rlere Ã§evrilir.
    * **VeritabanÄ±:** Bu vektÃ¶rler, bellekte (in-memory) tutulan `FAISS` VektÃ¶r VeritabanÄ±na kaydedilir.
3.  **Sorgu ve Cevap Ãœretimi (Generation):**
    * **Sorgu VektÃ¶rleme:** KullanÄ±cÄ±nÄ±n sorduÄŸu soru, aynÄ± lokal modelle vektÃ¶re Ã§evrilir.
    * **Alaka DÃ¼zeyi Arama (Retrieval):** VektÃ¶r veritabanÄ±nda, kullanÄ±cÄ±nÄ±n sorusuna en Ã§ok benzeyen (en alakalÄ±) metin parÃ§alarÄ± hÄ±zlÄ±ca bulunur.
    * **Ãœretim (Generation):** Bulunan bu alakalÄ± metin parÃ§alarÄ±, Gemini-2.5-Flash modeline gÃ¶nderilir. Model, bu parÃ§alarÄ± referans alarak sorunun cevabÄ±nÄ± Ã¼retir.

---

## ğŸš€ Kurulum ve Ã‡alÄ±ÅŸtÄ±rma KÄ±lavuzu

Bu proje, Python'Ä±n sanal ortamÄ± olan Conda kullanÄ±larak izole bir ortamda Ã§alÄ±ÅŸtÄ±rÄ±lmak Ã¼zere tasarlanmÄ±ÅŸtÄ±r.

### 1. Ã–n KoÅŸullar

1.  **Python:** Python 3.10 veya Ã¼zeri kurulu olmalÄ±dÄ±r.
2.  **Conda/Miniconda:** Sanal ortam yÃ¶netimi iÃ§in Conda veya Miniconda kurulu olmalÄ±dÄ±r.
3.  **Gemini API AnahtarÄ±:** Google AI Studio'dan edinilmiÅŸ geÃ§erli bir API anahtarÄ±.

### 2. Proje DosyalarÄ± ve YapÄ±sÄ±

Projenin anlaÅŸÄ±lÄ±rlÄ±ÄŸÄ±nÄ± artÄ±rmak iÃ§in aÅŸaÄŸÄ±daki temel dizin yapÄ±sÄ± kullanÄ±lÄ±r:
### 3. Ortam Kurulum AdÄ±mlarÄ±

Projenizi yerel bilgisayarÄ±nÄ±zda (Windows, Mac, Linux) Ã§alÄ±ÅŸtÄ±rmak iÃ§in aÅŸaÄŸÄ±daki adÄ±mlarÄ± sÄ±rasÄ±yla uygulayÄ±n.

1.  **Depoyu Klonlama:**
    ```bash
    git clone [https://github.com/ummuhanzenk/masal-chatbot-projesi.git](https://github.com/ummuhanzenk/masal-chatbot-projesi.git)
    cd masal-chatbot-projesi
    ```

2.  **Conda OrtamÄ± OluÅŸturma ve AktifleÅŸtirme:**
    ```bash
    conda create -n masal-conda python=3.10 -y
    conda activate masal-conda
    ```

3.  **BaÄŸÄ±mlÄ±lÄ±klarÄ± YÃ¼kleme:**
    ```bash
    pip install -r requirements.txt
    ```

4.  **API AnahtarÄ±nÄ± YapÄ±landÄ±rma:**
    * Proje klasÃ¶rÃ¼nÃ¼n iÃ§inde **`.env`** adÄ±nda bir dosya oluÅŸturun.
    * DosyanÄ±n iÃ§ine kendi Gemini API anahtarÄ±nÄ±zÄ± ekleyin (Ã–rnek satÄ±r):
        ```env
        # .env dosyasÄ± iÃ§eriÄŸi:
        GOOGLE_API_KEY="SÄ°ZÄ°N_API_ANAHTARINIZ"
        ```

5.  **UygulamayÄ± BaÅŸlatma:**
    ```bash
    python -m streamlit run project.py
    ```
    *Uygulama, yerel tarayÄ±cÄ±nÄ±zda otomatik olarak aÃ§Ä±lacaktÄ±r. Ä°lk Ã§alÄ±ÅŸtÄ±rmada lokal embedding modelini indirir.*

---

## ğŸŒ Web ArayÃ¼zÃ¼ ve ÃœrÃ¼n KÄ±lavuzu

Proje, kullanÄ±cÄ± dostu bir Streamlit arayÃ¼zÃ¼ ile sunulmaktadÄ±r.

### ÃœrÃ¼n Ã–zellikleri:

* **CanlÄ± Sohbet ArayÃ¼zÃ¼:** KullanÄ±cÄ±larÄ±n sorularÄ±nÄ± girmesi ve cevaplarÄ± gÃ¶rmesi iÃ§in modern bir Chatbot penceresi sunar.
* **Lokal VektÃ¶rleme Bildirimi:** Uygulama baÅŸlatÄ±lÄ±rken, verilerin lokal olarak iÅŸlendiÄŸi bilgisi ekranda gÃ¶sterilerek ÅŸeffaflÄ±k saÄŸlanÄ±r.
* **Otomatik YÃ¼kleme:** `masallar/` klasÃ¶rÃ¼ne yeni bir masal dosyasÄ± eklendiÄŸinde, uygulama yeniden baÅŸlatÄ±ldÄ±ÄŸÄ±nda otomatik olarak Ã¶ÄŸrenme sÃ¼recine dahil edilir.
* **Veri Seti Bilgisi:** ArayÃ¼z, kaÃ§ adet metin parÃ§asÄ±nÄ±n (chunks) iÅŸlendiÄŸini gÃ¶stererek kullanÄ±cÄ±nÄ±n bilgi kaynaÄŸÄ±nÄ±n bÃ¼yÃ¼klÃ¼ÄŸÃ¼nÃ¼ anlamasÄ±nÄ± saÄŸlar.

### KullanÄ±m KÄ±lavuzu:

1.  Uygulama baÅŸlatÄ±ldÄ±ÄŸÄ±nda, Ã¶ncelikle tÃ¼m masal metinleri yÃ¼klenir ve vektÃ¶rlenir (Ä°lk Ã§alÄ±ÅŸtÄ±rmada bu biraz zaman alabilir).
2.  Ä°ÅŸlem tamamlandÄ±ÄŸÄ±nda sohbet kutusu aktif hale gelir.
3.  **Soru Sorun:** "KÄ±rmÄ±zÄ± BaÅŸlÄ±klÄ± KÄ±z'Ä±n sepetinde ne vardÄ±?" gibi, yÃ¼klediÄŸiniz masallarla ilgili bir soru yazÄ±n ve Enter tuÅŸuna basÄ±n.
4.  LLM (Gemini-Flash), ilgili masal parÃ§alarÄ±nÄ± kullanarak size kanÄ±ta dayalÄ± bir cevap sunacaktÄ±r.
